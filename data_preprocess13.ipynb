{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data_preprocess13.ipynb\n",
    "作者：Ai<br>\n",
    "创建时间：2020.11.22<br>\n",
    "修改时间：2020.12.06<br>\n",
    "\n",
    "1. 时间格式转换：将DOTTING_TIME原格式转为UNIX时间格式(eda.ipynb已做)<br>\n",
    "2. 处理数据缺失<br>\n",
    "3. 处理重复样本<br>\n",
    "4. 特征工程1：获取交互特征'USED_CPU'已用CPU量和‘USED_MEM’已用内存量<br>\n",
    "5. 特征工程2：增加 小时/分钟 特征<br>\n",
    "6. 特征工程3：在每个时间点的样本特征中，加入历史4个时间点的特征值<br>\n",
    "7. 特征工程4：加入行内统计特征，即多阶的历史平均值,最大值,标准差,偏度,峰度和斜率<br>\n",
    "8. 特征工程5：获取交互特征'cancel_fail'\n",
    "9. 类别型变量独热编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import copy\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 时间格式转换\n",
    "将DOTTING_TIME原格式转为UNIX时间格式(eda.ipynb已做)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入转换好DOTTING_TIME的数据集\n",
    "train = pd.read_csv(\"../data/train1.csv\")\n",
    "test = pd.read_csv(\"../data/test1.csv\")\n",
    "\n",
    "# 经检验，为NaN的都是vm（通过QUEUE_ID查找）\n",
    "# train['RESOURCE_TYPE'].fillna('vm', inplace=True)\n",
    "train = train[train.STATUS == 'available']\n",
    "train = train[train.PLATFORM == 'x86_64']\n",
    "train = train[train.RESOURCE_TYPE == 'vm']\n",
    "train = train.reset_index(drop=True)\n",
    "\n",
    "train = train.sort_values(by = ['QUEUE_ID', 'DOTTING_TIME']).reset_index(drop=True)\n",
    "test = test.sort_values(by = ['ID', 'DOTTING_TIME']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 处理数据缺失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_miss_feats(data, method_no):\n",
    "    if method_no == 0:\n",
    "        # 暂时用0填补缺失值\n",
    "        # 观察数据，填充0比较合理（NaN集中在数据前面，可能是由服务器尚未开始运行导致的)\n",
    "        data['DISK_USAGE'] = data['DISK_USAGE'].fillna(0)\n",
    "        # 因为测试集的'RESOURCE_TYPE'只有单一值‘vm’，因此对应训练集不需要该特征了\n",
    "        del data['RESOURCE_TYPE']\n",
    "    elif method_no == 1:\n",
    "        del data['DISK_USAGE']\n",
    "        del data['RESOURCE_TYPE']\n",
    "    elif method_no == 2:\n",
    "        data['DISK_USAGE'] = data['DISK_USAGE'].fillna(0)\n",
    "        # 冗余无用特征(例如STATUS, QUEUE_TYPE和PLATFORM\n",
    "        del data['RESOURCE_TYPE']\n",
    "        del data['STATUS']\n",
    "        del data['PLATFORM']\n",
    "        del data['QUEUE_TYPE']\n",
    "    return data\n",
    "\n",
    "train = clean_miss_feats(train, 0)\n",
    "test = clean_miss_feats(test, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 处理重复样本\n",
    "目前有三种处理方式：<br>\n",
    "(1) 不处理；<br>\n",
    "(2) 若重复，只保留最后一个出现的重复项;<br>\n",
    "(3) 若重复，只保留第一个出现的重复项;<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deal_duplicate(data, method_no):\n",
    "    if method_no == 1:\n",
    "        pass\n",
    "    elif method_no == 2:\n",
    "        data.drop_duplicates(subset=['QUEUE_ID', 'CU', 'DOTTING_TIME'], keep='last', inplace=True)\n",
    "    elif method_no == 3:\n",
    "        data.drop_duplicates(subset=['QUEUE_ID', 'CU', 'DOTTING_TIME'], keep='first', inplace=True)\n",
    "    return data\n",
    "\n",
    "\n",
    "# 目前暂采用方法1：不处理\n",
    "train = deal_duplicate(train, 1)\n",
    "test = deal_duplicate(test, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 特征工程1：\n",
    "(1) 把‘CU’队列规格与'CPU_USAGE'和'MEM_USAGE'结合得到'USED_CPU'已用CPU量和‘USED_MEM’已用内存量<br>\n",
    "(2) TO_RUN_JOBS = LAUNCHING_JOB_NUMS - RUNNING_JOB_NUMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cu_extend_feat(data):\n",
    "    '''CPU核数×CPU利用率=已用CPU量；CPU多核下的内存大小x内存使用率=已用内存量'''\n",
    "    data['USED_CPU'] = data['CU'] * data['CPU_USAGE'] / 100\n",
    "    data['USED_MEM'] = data['CU'] * 4 * data['MEM_USAGE'] / 100\n",
    "    data['TO_RUN_JOBS'] = data['LAUNCHING_JOB_NUMS'] - data['RUNNING_JOB_NUMS']\n",
    "    return data\n",
    "\n",
    "train = cu_extend_feat(train)\n",
    "test = cu_extend_feat(test)\n",
    "\n",
    "del train['CU']\n",
    "del test['CU']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 特征工程2：\n",
    "增加 小时/分钟 特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 增加 小时 特征\n",
    "def add_hour_feat(df):\n",
    "    dotting_hours = []\n",
    "    for i in range(len(df)):\n",
    "        t = datetime.datetime.strptime(df['DOTTING_TIME'].iloc[i],'%Y-%m-%d %H:%M:%S')\n",
    "        dotting_hours.append(t.hour)\n",
    "    df['DOTTING_HOUR'] = dotting_hours\n",
    "\n",
    "# 增加 分钟 特征\n",
    "def add_minute_feat(df):\n",
    "    dotting_minutes = []\n",
    "    for i in range(len(df)):\n",
    "        t = datetime.datetime.strptime(df['DOTTING_TIME'].iloc[i],'%Y-%m-%d %H:%M:%S')\n",
    "        dotting_minutes.append(t.minute)\n",
    "    df['DOTTING_MINUTE'] = dotting_minutes    \n",
    "    \n",
    "# 增加 小时+分钟换算成小时 特征   \n",
    "def add_hour_plus_minute_feat(df):\n",
    "    dotting_hours = []\n",
    "    for i in range(len(df)):\n",
    "        t = datetime.datetime.strptime(df['DOTTING_TIME'].iloc[i],'%Y-%m-%d %H:%M:%S')\n",
    "        dotting_hours.append(t.hour + t.minute/60)\n",
    "    df['DOTTING_HOUR'] = dotting_hours\n",
    "    \n",
    "add_hour_feat(train)\n",
    "add_hour_feat(test)\n",
    "add_minute_feat(train)\n",
    "add_minute_feat(test)\n",
    "# add_hour_plus_minute_feat(train)\n",
    "# add_hour_plus_minute_feat(test)\n",
    "\n",
    "# 'DOTTING_TIME'不需要了\n",
    "del train['DOTTING_TIME']\n",
    "del test['DOTTING_TIME']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 特征工程3：\n",
    "在每个时间点的样本特征中，加入历史5个时间点的特征值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 1/40 [00:00<00:14,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEUE_ID: 2, lines: 19245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 2/40 [00:00<00:13,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEUE_ID: 3, lines: 19247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 3/40 [00:01<00:14,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEUE_ID: 4, lines: 19247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 4/40 [00:01<00:12,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEUE_ID: 26, lines: 10397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 5/40 [00:01<00:11,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEUE_ID: 27, lines: 10516\n",
      "QUEUE_ID: 36, lines: 3232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 7/40 [00:01<00:07,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEUE_ID: 233, lines: 2089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 8/40 [00:02<00:07,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEUE_ID: 281, lines: 10355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▎       | 9/40 [00:02<00:07,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEUE_ID: 287, lines: 6866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 10/40 [00:02<00:08,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEUE_ID: 291, lines: 8874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 11/40 [00:03<00:07,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEUE_ID: 293, lines: 8845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 12/40 [00:03<00:09,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEUE_ID: 297, lines: 19220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▎      | 13/40 [00:04<00:10,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEUE_ID: 298, lines: 19355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 14/40 [00:04<00:09,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEUE_ID: 20889, lines: 10710\n",
      "QUEUE_ID: 21487, lines: 15043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 15/40 [00:04<00:10,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEUE_ID: 21671, lines: 15932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 16/40 [00:05<00:10,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEUE_ID: 21673, lines: 19713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▎     | 17/40 [00:06<00:11,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEUE_ID: 21825, lines: 19713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 18/40 [00:06<00:12,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEUE_ID: 81221, lines: 19713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 19/40 [00:07<00:11,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEUE_ID: 82695, lines: 19713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 20/40 [00:08<00:12,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEUE_ID: 82697, lines: 10441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▎    | 21/40 [00:08<00:11,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEUE_ID: 82929, lines: 9717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 22/40 [00:09<00:10,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEUE_ID: 83109, lines: 8922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▊    | 23/40 [00:09<00:09,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEUE_ID: 83609, lines: 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 24/40 [00:10<00:08,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEUE_ID: 84387, lines: 17510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▎   | 25/40 [00:10<00:08,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEUE_ID: 84907, lines: 6485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 26/40 [00:11<00:08,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEUE_ID: 85101, lines: 6608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 27/40 [00:11<00:07,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEUE_ID: 85153, lines: 14343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 28/40 [00:12<00:07,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEUE_ID: 85265, lines: 13506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▎  | 29/40 [00:13<00:07,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEUE_ID: 85267, lines: 13072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 30/40 [00:14<00:06,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEUE_ID: 85619, lines: 9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 31/40 [00:14<00:05,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEUE_ID: 85693, lines: 10824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 32/40 [00:15<00:05,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEUE_ID: 85731, lines: 8558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▎ | 33/40 [00:16<00:04,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEUE_ID: 85781, lines: 1139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 34/40 [00:16<00:03,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEUE_ID: 85915, lines: 9210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 35/40 [00:17<00:03,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEUE_ID: 85933, lines: 8801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 36/40 [00:17<00:02,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEUE_ID: 85977, lines: 8783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▎| 37/40 [00:18<00:01,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEUE_ID: 86865, lines: 3534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 38/40 [00:19<00:01,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEUE_ID: 86867, lines: 3743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 39/40 [00:19<00:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEUE_ID: 87139, lines: 2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:20<00:00,  1.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# t0 t1 t2 t3 t4  ->  t5 t6 t7 t8 t9 \n",
    "# t1 t2 t3 t4 t5  ->  t6 t7 t8 t9 t10\n",
    "\n",
    "# 获取要加入历史4个时间点的特征\n",
    "hist_feats = []\n",
    "for i in range(1, 6):\n",
    "    for f in list(train.iloc[:,1:]):\n",
    "        hist_feats.append(f + '_' + str(i))\n",
    "\n",
    "# 对训练集加入历史4个时间点的特征\n",
    "df_train = pd.DataFrame()\n",
    "for id_ in tqdm(train['QUEUE_ID'].unique()):\n",
    "    df_tmp = train[train['QUEUE_ID'] == id_]\n",
    "    features = list()\n",
    "    t_cpu = list()\n",
    "    values = df_tmp.values\n",
    "    for i, _ in enumerate(values):\n",
    "        if i + 10 < len(values):\n",
    "            li_v = list()\n",
    "            li_v.append(values[i][0])\n",
    "            li_cpu = list()\n",
    "            for j in range(5):\n",
    "                # 这里加入所有历史4个时间点的特征，而不像baseline_v3只关注CPU_USAGE和MEM_USAGE\n",
    "                li_v.extend(values[i+j][1:].tolist())\n",
    "                # CPU_USAGE的位置在第4列（0-based indexing）\n",
    "                li_cpu.append(values[i+j+5][4])\n",
    "            features.append(li_v)\n",
    "            t_cpu.append(li_cpu)\n",
    "    df_feat = pd.DataFrame(features)\n",
    "    df_feat.columns = ['QUEUE_ID'] + hist_feats\n",
    "    df_cpu = pd.DataFrame(t_cpu)\n",
    "    df_cpu.columns = ['cpu_1', 'cpu_2', 'cpu_3', 'cpu_4', 'cpu_5']\n",
    "    df = pd.concat([df_feat, df_cpu], axis=1)\n",
    "    print(f'QUEUE_ID: {id_}, lines: {df.shape[0]}')\n",
    "    df_train = df_train.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 9/23 [00:00<00:00, 23.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEUE_ID: 297, lines: 1142\n",
      "QUEUE_ID: 85153, lines: 390\n",
      "QUEUE_ID: 291, lines: 57\n",
      "QUEUE_ID: 21487, lines: 447\n",
      "QUEUE_ID: 85265, lines: 19\n",
      "QUEUE_ID: 4, lines: 151\n",
      "QUEUE_ID: 2, lines: 151\n",
      "QUEUE_ID: 81221, lines: 52\n",
      "QUEUE_ID: 287, lines: 53\n",
      "QUEUE_ID: 85693, lines: 24\n",
      "QUEUE_ID: 3, lines: 156\n",
      "QUEUE_ID: 293, lines: 51\n",
      "QUEUE_ID: 36, lines: 33\n",
      "QUEUE_ID: 26, lines: 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:00<00:00, 56.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEUE_ID: 281, lines: 100\n",
      "QUEUE_ID: 83609, lines: 3\n",
      "QUEUE_ID: 21671, lines: 29\n",
      "QUEUE_ID: 27, lines: 57\n",
      "QUEUE_ID: 233, lines: 11\n",
      "QUEUE_ID: 85101, lines: 2\n",
      "QUEUE_ID: 85933, lines: 4\n",
      "QUEUE_ID: 21673, lines: 4\n",
      "QUEUE_ID: 298, lines: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# t0 t1 t2 t3 t4  ->  t5 t6 t7 t8 t9 \n",
    "# t10 t11 t12 t13 t14  ->  t15 t16 t17 t18 t19\n",
    "df_test = pd.DataFrame()\n",
    "for id_ in tqdm(test['QUEUE_ID'].unique()):\n",
    "    df_tmp = test[test['QUEUE_ID'] == id_]\n",
    "    features = list()\n",
    "    values = df_tmp.values\n",
    "    for i, _ in enumerate(values):\n",
    "        if i % 5 == 0:\n",
    "            li_v = list()\n",
    "            li_v.append(values[i][0])\n",
    "            li_v.append(values[i][1])\n",
    "            for j in range(5):\n",
    "                # 这里加入所有历史5个时间点的特征，而不像baseline_v3只关注CPU_USAGE和MEM_USAGE\n",
    "                li_v.extend(values[i+j][2:].tolist())\n",
    "            features.append(li_v)\n",
    "    df_feat = pd.DataFrame(features)\n",
    "    df_feat.columns = ['ID', 'QUEUE_ID'] + hist_feats\n",
    "    df = df_feat.copy()\n",
    "    print(f'QUEUE_ID: {id_}, lines: {df.shape[0]}')\n",
    "    df_test = df_test.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 特征工程4：\n",
    "加入行内统计特征，即考虑多阶的历史平均值,最大值,标准差,偏度,峰度和斜率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 类别型数据\n",
    "cat_feats = ['ID',\n",
    "             'QUEUE_ID',\n",
    "             'DOTTING_HOUR_1', 'DOTTING_HOUR_2', 'DOTTING_HOUR_3', 'DOTTING_HOUR_4', 'DOTTING_HOUR_5',\n",
    "             'DOTTING_MINUTE_1', 'DOTTING_MINUTE_2', 'DOTTING_MINUTE_3', 'DOTTING_MINUTE_4', 'DOTTING_MINUTE_5',\n",
    "             'STATUS_1', 'QUEUE_TYPE_1', 'PLATFORM_1',\n",
    "             'STATUS_2', 'QUEUE_TYPE_2', 'PLATFORM_2',\n",
    "             'STATUS_3', 'QUEUE_TYPE_3', 'PLATFORM_3',\n",
    "             'STATUS_4', 'QUEUE_TYPE_4', 'PLATFORM_4',\n",
    "             'STATUS_5', 'QUEUE_TYPE_5', 'PLATFORM_5']\n",
    "\n",
    "# 去除类别型数据\n",
    "cont_feats = [f for f in list(df_train) if f not in cat_feats]\n",
    "# 去除含后缀‘_{数字}’的连续型特征\n",
    "cont_feats_no_postfix = []\n",
    "for f in cont_feats:\n",
    "    if f.split('_')[-1] in ['1','2','3','4','5'] and f.startswith('cpu_') != True:\n",
    "        cont_feats_no_postfix.append(f[:-2])\n",
    "cont_feats_no_postfix = np.unique(cont_feats_no_postfix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "增加1阶行内统计特征\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 1/4 [00:01<00:05,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "增加2阶行内统计特征\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 2/4 [00:04<00:03,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "增加3阶行内统计特征\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 3/4 [00:11<00:03,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "增加4阶行内统计特征\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:20<00:00,  5.18s/it]\n"
     ]
    }
   ],
   "source": [
    "del train\n",
    "del test\n",
    "\n",
    "def add_stat_feats(data, diff_num, cont_feats):\n",
    "    '''针对给定数据集加入给定阶数的行内统计特征\n",
    "    输入：\n",
    "        1. data        (pd.DataFrame):数据集\n",
    "        2. diff_num             (int):阶数(可选1/2/3/4)\n",
    "        3. cont_feats          (list):连续型变量（无后缀_{num}）名称列表\n",
    "    输出：\n",
    "        1. data        (pd.DataFrame):加入行内统计特征的数据集\n",
    "    '''\n",
    "    for f in cont_feats:\n",
    "\n",
    "        # 实验19：采用手工加权平均，当前时间节点权重最大，越往历史前进，权重越小\n",
    "        if diff_num == 1:\n",
    "            data[f + '_' + str(diff_num) + '_mean'] = data[f+'_4']*0.3 + data[f+'_5']*0.7\n",
    "        elif diff_num == 2:\n",
    "            data[f + '_' + str(diff_num) + '_mean'] = data[f+'_3']*0.1 + data[f+'_4']*0.2 + data[f+'_5']*0.7\n",
    "        elif diff_num == 3:\n",
    "            data[f + '_' + str(diff_num) + '_mean'] = data[f+'_2']*0.05 + data[f+'_3']*0.1 + data[f+'_4']*0.15 + data[f+'_5']*0.7\n",
    "        elif diff_num == 4:\n",
    "            data[f + '_' + str(diff_num) + '_mean'] = data[f+'_1']*0.055 + data[f+'_2']*0.07 + data[f+'_3']*0.075 + data[f+'_4']*0.1 + data[f+'_5']*0.7            \n",
    "        \n",
    "        data[f + '_' + str(diff_num) + '_std'] = data[[f + f'_{i}' for i in range(5-diff_num, 6)]].std(axis=1)\n",
    "        data[f + '_' + str(diff_num) + '_max'] = data[[f + f'_{i}' for i in range(5-diff_num, 6)]].max(axis=1)\n",
    "        \n",
    "        # 因为3个时间点样本会返回无偏峰度，因此这里不对1/2阶进行统计\n",
    "        if diff_num >= 3:\n",
    "            data[f + '_' + str(diff_num) + '_skew'] = data[[f + f'_{i}' for i in range(5-diff_num, 6)]].skew(axis=1)\n",
    "            data[f + '_' + str(diff_num) + '_kurt'] = data[[f + f'_{i}' for i in range(5-diff_num, 6)]].kurt(axis=1)\n",
    "        \n",
    "        # 求最近一阶斜率 = (feat_5 - feat_4) / 5mins\n",
    "        if diff_num == 1:\n",
    "            data[f + '_slope'] = (data[f + f'_{5}'] - data[f + f'_{4}']) / 5    \n",
    "            \n",
    "    return data\n",
    "\n",
    "for i in tqdm([1,2,3]):\n",
    "    print('增加%d阶行内统计特征' % i)\n",
    "    df_train = add_stat_feats(df_train, i, cont_feats_no_postfix)\n",
    "    df_test = add_stat_feats(df_test, i, cont_feats_no_postfix)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 特征工程5：\n",
    "增加交互特征：cancel_fail = CANCELLED_JOB_NUMS - FAILED_JOB_NUMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 增加交互特征\n",
    "for i in range(1,6):\n",
    "    df_train['cancel_fail_' + str(i)] =  df_train['CANCELLED_JOB_NUMS_' + str(i)] - df_train['FAILED_JOB_NUMS_' + str(i)]\n",
    "    df_test['cancel_fail_' + str(i)] =  df_test['CANCELLED_JOB_NUMS_' + str(i)] - df_test['FAILED_JOB_NUMS_' + str(i)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. 类别型变量标签编码\n",
    "1. 树模型对于特征量纲没有要求，连续特征，类别型特征都不要归一化操作 \n",
    "- 一是因为树模型不是利用SGD等优化算法进行优化； \n",
    "- 二是LightGBM中回归树生长过程中，是利用特征的直方图寻找最优的特征，以及分裂点，因此这个过程只关心取值的顺序，即使归一化之后，各个样本的取值的顺序依然不会改变，所以没有必要；\n",
    "2. 对于类别型的特征，传统的机器学习模型是需要先利用one-hot编码，而在LightGBM中只需要提前将类别映射到非负整数即可(`integer-encoded categorical features`)，例如，进行如下编码mapping`{'川建国': 1, '傻蛋': 2, '其他': 0}`，在官方文档中也建议使用从0开始的连续的数值进行编码，当训练集中的某个类别型的特征取值个数超大，可以将其看做是连续特征看待，或者进行embedding编码。\n",
    "**作者：一直学习一直爽(知乎)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450595, 274)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 合并训练集和测试集，让其在统一样本空间下进行独热，保证独热编码的一致性\n",
    "train_test = pd.concat([df_train, df_test], axis=0, sort=False)\n",
    "\n",
    "# 类别型变量独热编码\n",
    "le = LabelEncoder()\n",
    "for i in cat_feats:\n",
    "    if i != 'ID':\n",
    "        train_test[i] = le.fit_transform(train_test[i].astype(str))\n",
    "\n",
    "# 拆分数据集：ID为空的是训练集，反之为测试集\n",
    "df_train = train_test[train_test['ID'].isna()==True]\n",
    "df_train = df_train.drop('ID', axis = 1)\n",
    "df_test = train_test[train_test['ID'].isna()==False]\n",
    "\n",
    "df_train = df_train.reset_index(drop = True)\n",
    "df_test = df_test.reset_index(drop = True)\n",
    "train_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train(273个变量：['QUEUE_ID', 'STATUS_1', 'QUEUE_TYPE_1', 'PLATFORM_1', 'CPU_USAGE_1', 'MEM_USAGE_1', 'LAUNCHING_JOB_NUMS_1', 'RUNNING_JOB_NUMS_1', 'SUCCEED_JOB_NUMS_1', 'CANCELLED_JOB_NUMS_1', 'FAILED_JOB_NUMS_1', 'DISK_USAGE_1', 'USED_CPU_1', 'USED_MEM_1', 'TO_RUN_JOBS_1', 'DOTTING_HOUR_1', 'DOTTING_MINUTE_1', 'STATUS_2', 'QUEUE_TYPE_2', 'PLATFORM_2', 'CPU_USAGE_2', 'MEM_USAGE_2', 'LAUNCHING_JOB_NUMS_2', 'RUNNING_JOB_NUMS_2', 'SUCCEED_JOB_NUMS_2', 'CANCELLED_JOB_NUMS_2', 'FAILED_JOB_NUMS_2', 'DISK_USAGE_2', 'USED_CPU_2', 'USED_MEM_2', 'TO_RUN_JOBS_2', 'DOTTING_HOUR_2', 'DOTTING_MINUTE_2', 'STATUS_3', 'QUEUE_TYPE_3', 'PLATFORM_3', 'CPU_USAGE_3', 'MEM_USAGE_3', 'LAUNCHING_JOB_NUMS_3', 'RUNNING_JOB_NUMS_3', 'SUCCEED_JOB_NUMS_3', 'CANCELLED_JOB_NUMS_3', 'FAILED_JOB_NUMS_3', 'DISK_USAGE_3', 'USED_CPU_3', 'USED_MEM_3', 'TO_RUN_JOBS_3', 'DOTTING_HOUR_3', 'DOTTING_MINUTE_3', 'STATUS_4', 'QUEUE_TYPE_4', 'PLATFORM_4', 'CPU_USAGE_4', 'MEM_USAGE_4', 'LAUNCHING_JOB_NUMS_4', 'RUNNING_JOB_NUMS_4', 'SUCCEED_JOB_NUMS_4', 'CANCELLED_JOB_NUMS_4', 'FAILED_JOB_NUMS_4', 'DISK_USAGE_4', 'USED_CPU_4', 'USED_MEM_4', 'TO_RUN_JOBS_4', 'DOTTING_HOUR_4', 'DOTTING_MINUTE_4', 'STATUS_5', 'QUEUE_TYPE_5', 'PLATFORM_5', 'CPU_USAGE_5', 'MEM_USAGE_5', 'LAUNCHING_JOB_NUMS_5', 'RUNNING_JOB_NUMS_5', 'SUCCEED_JOB_NUMS_5', 'CANCELLED_JOB_NUMS_5', 'FAILED_JOB_NUMS_5', 'DISK_USAGE_5', 'USED_CPU_5', 'USED_MEM_5', 'TO_RUN_JOBS_5', 'DOTTING_HOUR_5', 'DOTTING_MINUTE_5', 'cpu_1', 'cpu_2', 'cpu_3', 'cpu_4', 'cpu_5', 'CANCELLED_JOB_NUMS_1_mean', 'CANCELLED_JOB_NUMS_1_std', 'CANCELLED_JOB_NUMS_1_max', 'CANCELLED_JOB_NUMS_slope', 'CPU_USAGE_1_mean', 'CPU_USAGE_1_std', 'CPU_USAGE_1_max', 'CPU_USAGE_slope', 'DISK_USAGE_1_mean', 'DISK_USAGE_1_std', 'DISK_USAGE_1_max', 'DISK_USAGE_slope', 'FAILED_JOB_NUMS_1_mean', 'FAILED_JOB_NUMS_1_std', 'FAILED_JOB_NUMS_1_max', 'FAILED_JOB_NUMS_slope', 'LAUNCHING_JOB_NUMS_1_mean', 'LAUNCHING_JOB_NUMS_1_std', 'LAUNCHING_JOB_NUMS_1_max', 'LAUNCHING_JOB_NUMS_slope', 'MEM_USAGE_1_mean', 'MEM_USAGE_1_std', 'MEM_USAGE_1_max', 'MEM_USAGE_slope', 'RUNNING_JOB_NUMS_1_mean', 'RUNNING_JOB_NUMS_1_std', 'RUNNING_JOB_NUMS_1_max', 'RUNNING_JOB_NUMS_slope', 'SUCCEED_JOB_NUMS_1_mean', 'SUCCEED_JOB_NUMS_1_std', 'SUCCEED_JOB_NUMS_1_max', 'SUCCEED_JOB_NUMS_slope', 'TO_RUN_JOBS_1_mean', 'TO_RUN_JOBS_1_std', 'TO_RUN_JOBS_1_max', 'TO_RUN_JOBS_slope', 'USED_CPU_1_mean', 'USED_CPU_1_std', 'USED_CPU_1_max', 'USED_CPU_slope', 'USED_MEM_1_mean', 'USED_MEM_1_std', 'USED_MEM_1_max', 'USED_MEM_slope', 'CANCELLED_JOB_NUMS_2_mean', 'CANCELLED_JOB_NUMS_2_std', 'CANCELLED_JOB_NUMS_2_max', 'CPU_USAGE_2_mean', 'CPU_USAGE_2_std', 'CPU_USAGE_2_max', 'DISK_USAGE_2_mean', 'DISK_USAGE_2_std', 'DISK_USAGE_2_max', 'FAILED_JOB_NUMS_2_mean', 'FAILED_JOB_NUMS_2_std', 'FAILED_JOB_NUMS_2_max', 'LAUNCHING_JOB_NUMS_2_mean', 'LAUNCHING_JOB_NUMS_2_std', 'LAUNCHING_JOB_NUMS_2_max', 'MEM_USAGE_2_mean', 'MEM_USAGE_2_std', 'MEM_USAGE_2_max', 'RUNNING_JOB_NUMS_2_mean', 'RUNNING_JOB_NUMS_2_std', 'RUNNING_JOB_NUMS_2_max', 'SUCCEED_JOB_NUMS_2_mean', 'SUCCEED_JOB_NUMS_2_std', 'SUCCEED_JOB_NUMS_2_max', 'TO_RUN_JOBS_2_mean', 'TO_RUN_JOBS_2_std', 'TO_RUN_JOBS_2_max', 'USED_CPU_2_mean', 'USED_CPU_2_std', 'USED_CPU_2_max', 'USED_MEM_2_mean', 'USED_MEM_2_std', 'USED_MEM_2_max', 'CANCELLED_JOB_NUMS_3_mean', 'CANCELLED_JOB_NUMS_3_std', 'CANCELLED_JOB_NUMS_3_max', 'CANCELLED_JOB_NUMS_3_skew', 'CANCELLED_JOB_NUMS_3_kurt', 'CPU_USAGE_3_mean', 'CPU_USAGE_3_std', 'CPU_USAGE_3_max', 'CPU_USAGE_3_skew', 'CPU_USAGE_3_kurt', 'DISK_USAGE_3_mean', 'DISK_USAGE_3_std', 'DISK_USAGE_3_max', 'DISK_USAGE_3_skew', 'DISK_USAGE_3_kurt', 'FAILED_JOB_NUMS_3_mean', 'FAILED_JOB_NUMS_3_std', 'FAILED_JOB_NUMS_3_max', 'FAILED_JOB_NUMS_3_skew', 'FAILED_JOB_NUMS_3_kurt', 'LAUNCHING_JOB_NUMS_3_mean', 'LAUNCHING_JOB_NUMS_3_std', 'LAUNCHING_JOB_NUMS_3_max', 'LAUNCHING_JOB_NUMS_3_skew', 'LAUNCHING_JOB_NUMS_3_kurt', 'MEM_USAGE_3_mean', 'MEM_USAGE_3_std', 'MEM_USAGE_3_max', 'MEM_USAGE_3_skew', 'MEM_USAGE_3_kurt', 'RUNNING_JOB_NUMS_3_mean', 'RUNNING_JOB_NUMS_3_std', 'RUNNING_JOB_NUMS_3_max', 'RUNNING_JOB_NUMS_3_skew', 'RUNNING_JOB_NUMS_3_kurt', 'SUCCEED_JOB_NUMS_3_mean', 'SUCCEED_JOB_NUMS_3_std', 'SUCCEED_JOB_NUMS_3_max', 'SUCCEED_JOB_NUMS_3_skew', 'SUCCEED_JOB_NUMS_3_kurt', 'TO_RUN_JOBS_3_mean', 'TO_RUN_JOBS_3_std', 'TO_RUN_JOBS_3_max', 'TO_RUN_JOBS_3_skew', 'TO_RUN_JOBS_3_kurt', 'USED_CPU_3_mean', 'USED_CPU_3_std', 'USED_CPU_3_max', 'USED_CPU_3_skew', 'USED_CPU_3_kurt', 'USED_MEM_3_mean', 'USED_MEM_3_std', 'USED_MEM_3_max', 'USED_MEM_3_skew', 'USED_MEM_3_kurt', 'CANCELLED_JOB_NUMS_4_mean', 'CANCELLED_JOB_NUMS_4_std', 'CANCELLED_JOB_NUMS_4_max', 'CANCELLED_JOB_NUMS_4_skew', 'CANCELLED_JOB_NUMS_4_kurt', 'CPU_USAGE_4_mean', 'CPU_USAGE_4_std', 'CPU_USAGE_4_max', 'CPU_USAGE_4_skew', 'CPU_USAGE_4_kurt', 'DISK_USAGE_4_mean', 'DISK_USAGE_4_std', 'DISK_USAGE_4_max', 'DISK_USAGE_4_skew', 'DISK_USAGE_4_kurt', 'FAILED_JOB_NUMS_4_mean', 'FAILED_JOB_NUMS_4_std', 'FAILED_JOB_NUMS_4_max', 'FAILED_JOB_NUMS_4_skew', 'FAILED_JOB_NUMS_4_kurt', 'LAUNCHING_JOB_NUMS_4_mean', 'LAUNCHING_JOB_NUMS_4_std', 'LAUNCHING_JOB_NUMS_4_max', 'LAUNCHING_JOB_NUMS_4_skew', 'LAUNCHING_JOB_NUMS_4_kurt', 'MEM_USAGE_4_mean', 'MEM_USAGE_4_std', 'MEM_USAGE_4_max', 'MEM_USAGE_4_skew', 'MEM_USAGE_4_kurt', 'RUNNING_JOB_NUMS_4_mean', 'RUNNING_JOB_NUMS_4_std', 'RUNNING_JOB_NUMS_4_max', 'RUNNING_JOB_NUMS_4_skew', 'RUNNING_JOB_NUMS_4_kurt', 'SUCCEED_JOB_NUMS_4_mean', 'SUCCEED_JOB_NUMS_4_std', 'SUCCEED_JOB_NUMS_4_max', 'SUCCEED_JOB_NUMS_4_skew', 'SUCCEED_JOB_NUMS_4_kurt', 'TO_RUN_JOBS_4_mean', 'TO_RUN_JOBS_4_std', 'TO_RUN_JOBS_4_max', 'TO_RUN_JOBS_4_skew', 'TO_RUN_JOBS_4_kurt', 'USED_CPU_4_mean', 'USED_CPU_4_std', 'USED_CPU_4_max', 'USED_CPU_4_skew', 'USED_CPU_4_kurt', 'USED_MEM_4_mean', 'USED_MEM_4_std', 'USED_MEM_4_max', 'USED_MEM_4_skew', 'USED_MEM_4_kurt']\n",
      "==================================================\n",
      "df_test(274个变量：['QUEUE_ID', 'STATUS_1', 'QUEUE_TYPE_1', 'PLATFORM_1', 'CPU_USAGE_1', 'MEM_USAGE_1', 'LAUNCHING_JOB_NUMS_1', 'RUNNING_JOB_NUMS_1', 'SUCCEED_JOB_NUMS_1', 'CANCELLED_JOB_NUMS_1', 'FAILED_JOB_NUMS_1', 'DISK_USAGE_1', 'USED_CPU_1', 'USED_MEM_1', 'TO_RUN_JOBS_1', 'DOTTING_HOUR_1', 'DOTTING_MINUTE_1', 'STATUS_2', 'QUEUE_TYPE_2', 'PLATFORM_2', 'CPU_USAGE_2', 'MEM_USAGE_2', 'LAUNCHING_JOB_NUMS_2', 'RUNNING_JOB_NUMS_2', 'SUCCEED_JOB_NUMS_2', 'CANCELLED_JOB_NUMS_2', 'FAILED_JOB_NUMS_2', 'DISK_USAGE_2', 'USED_CPU_2', 'USED_MEM_2', 'TO_RUN_JOBS_2', 'DOTTING_HOUR_2', 'DOTTING_MINUTE_2', 'STATUS_3', 'QUEUE_TYPE_3', 'PLATFORM_3', 'CPU_USAGE_3', 'MEM_USAGE_3', 'LAUNCHING_JOB_NUMS_3', 'RUNNING_JOB_NUMS_3', 'SUCCEED_JOB_NUMS_3', 'CANCELLED_JOB_NUMS_3', 'FAILED_JOB_NUMS_3', 'DISK_USAGE_3', 'USED_CPU_3', 'USED_MEM_3', 'TO_RUN_JOBS_3', 'DOTTING_HOUR_3', 'DOTTING_MINUTE_3', 'STATUS_4', 'QUEUE_TYPE_4', 'PLATFORM_4', 'CPU_USAGE_4', 'MEM_USAGE_4', 'LAUNCHING_JOB_NUMS_4', 'RUNNING_JOB_NUMS_4', 'SUCCEED_JOB_NUMS_4', 'CANCELLED_JOB_NUMS_4', 'FAILED_JOB_NUMS_4', 'DISK_USAGE_4', 'USED_CPU_4', 'USED_MEM_4', 'TO_RUN_JOBS_4', 'DOTTING_HOUR_4', 'DOTTING_MINUTE_4', 'STATUS_5', 'QUEUE_TYPE_5', 'PLATFORM_5', 'CPU_USAGE_5', 'MEM_USAGE_5', 'LAUNCHING_JOB_NUMS_5', 'RUNNING_JOB_NUMS_5', 'SUCCEED_JOB_NUMS_5', 'CANCELLED_JOB_NUMS_5', 'FAILED_JOB_NUMS_5', 'DISK_USAGE_5', 'USED_CPU_5', 'USED_MEM_5', 'TO_RUN_JOBS_5', 'DOTTING_HOUR_5', 'DOTTING_MINUTE_5', 'cpu_1', 'cpu_2', 'cpu_3', 'cpu_4', 'cpu_5', 'CANCELLED_JOB_NUMS_1_mean', 'CANCELLED_JOB_NUMS_1_std', 'CANCELLED_JOB_NUMS_1_max', 'CANCELLED_JOB_NUMS_slope', 'CPU_USAGE_1_mean', 'CPU_USAGE_1_std', 'CPU_USAGE_1_max', 'CPU_USAGE_slope', 'DISK_USAGE_1_mean', 'DISK_USAGE_1_std', 'DISK_USAGE_1_max', 'DISK_USAGE_slope', 'FAILED_JOB_NUMS_1_mean', 'FAILED_JOB_NUMS_1_std', 'FAILED_JOB_NUMS_1_max', 'FAILED_JOB_NUMS_slope', 'LAUNCHING_JOB_NUMS_1_mean', 'LAUNCHING_JOB_NUMS_1_std', 'LAUNCHING_JOB_NUMS_1_max', 'LAUNCHING_JOB_NUMS_slope', 'MEM_USAGE_1_mean', 'MEM_USAGE_1_std', 'MEM_USAGE_1_max', 'MEM_USAGE_slope', 'RUNNING_JOB_NUMS_1_mean', 'RUNNING_JOB_NUMS_1_std', 'RUNNING_JOB_NUMS_1_max', 'RUNNING_JOB_NUMS_slope', 'SUCCEED_JOB_NUMS_1_mean', 'SUCCEED_JOB_NUMS_1_std', 'SUCCEED_JOB_NUMS_1_max', 'SUCCEED_JOB_NUMS_slope', 'TO_RUN_JOBS_1_mean', 'TO_RUN_JOBS_1_std', 'TO_RUN_JOBS_1_max', 'TO_RUN_JOBS_slope', 'USED_CPU_1_mean', 'USED_CPU_1_std', 'USED_CPU_1_max', 'USED_CPU_slope', 'USED_MEM_1_mean', 'USED_MEM_1_std', 'USED_MEM_1_max', 'USED_MEM_slope', 'CANCELLED_JOB_NUMS_2_mean', 'CANCELLED_JOB_NUMS_2_std', 'CANCELLED_JOB_NUMS_2_max', 'CPU_USAGE_2_mean', 'CPU_USAGE_2_std', 'CPU_USAGE_2_max', 'DISK_USAGE_2_mean', 'DISK_USAGE_2_std', 'DISK_USAGE_2_max', 'FAILED_JOB_NUMS_2_mean', 'FAILED_JOB_NUMS_2_std', 'FAILED_JOB_NUMS_2_max', 'LAUNCHING_JOB_NUMS_2_mean', 'LAUNCHING_JOB_NUMS_2_std', 'LAUNCHING_JOB_NUMS_2_max', 'MEM_USAGE_2_mean', 'MEM_USAGE_2_std', 'MEM_USAGE_2_max', 'RUNNING_JOB_NUMS_2_mean', 'RUNNING_JOB_NUMS_2_std', 'RUNNING_JOB_NUMS_2_max', 'SUCCEED_JOB_NUMS_2_mean', 'SUCCEED_JOB_NUMS_2_std', 'SUCCEED_JOB_NUMS_2_max', 'TO_RUN_JOBS_2_mean', 'TO_RUN_JOBS_2_std', 'TO_RUN_JOBS_2_max', 'USED_CPU_2_mean', 'USED_CPU_2_std', 'USED_CPU_2_max', 'USED_MEM_2_mean', 'USED_MEM_2_std', 'USED_MEM_2_max', 'CANCELLED_JOB_NUMS_3_mean', 'CANCELLED_JOB_NUMS_3_std', 'CANCELLED_JOB_NUMS_3_max', 'CANCELLED_JOB_NUMS_3_skew', 'CANCELLED_JOB_NUMS_3_kurt', 'CPU_USAGE_3_mean', 'CPU_USAGE_3_std', 'CPU_USAGE_3_max', 'CPU_USAGE_3_skew', 'CPU_USAGE_3_kurt', 'DISK_USAGE_3_mean', 'DISK_USAGE_3_std', 'DISK_USAGE_3_max', 'DISK_USAGE_3_skew', 'DISK_USAGE_3_kurt', 'FAILED_JOB_NUMS_3_mean', 'FAILED_JOB_NUMS_3_std', 'FAILED_JOB_NUMS_3_max', 'FAILED_JOB_NUMS_3_skew', 'FAILED_JOB_NUMS_3_kurt', 'LAUNCHING_JOB_NUMS_3_mean', 'LAUNCHING_JOB_NUMS_3_std', 'LAUNCHING_JOB_NUMS_3_max', 'LAUNCHING_JOB_NUMS_3_skew', 'LAUNCHING_JOB_NUMS_3_kurt', 'MEM_USAGE_3_mean', 'MEM_USAGE_3_std', 'MEM_USAGE_3_max', 'MEM_USAGE_3_skew', 'MEM_USAGE_3_kurt', 'RUNNING_JOB_NUMS_3_mean', 'RUNNING_JOB_NUMS_3_std', 'RUNNING_JOB_NUMS_3_max', 'RUNNING_JOB_NUMS_3_skew', 'RUNNING_JOB_NUMS_3_kurt', 'SUCCEED_JOB_NUMS_3_mean', 'SUCCEED_JOB_NUMS_3_std', 'SUCCEED_JOB_NUMS_3_max', 'SUCCEED_JOB_NUMS_3_skew', 'SUCCEED_JOB_NUMS_3_kurt', 'TO_RUN_JOBS_3_mean', 'TO_RUN_JOBS_3_std', 'TO_RUN_JOBS_3_max', 'TO_RUN_JOBS_3_skew', 'TO_RUN_JOBS_3_kurt', 'USED_CPU_3_mean', 'USED_CPU_3_std', 'USED_CPU_3_max', 'USED_CPU_3_skew', 'USED_CPU_3_kurt', 'USED_MEM_3_mean', 'USED_MEM_3_std', 'USED_MEM_3_max', 'USED_MEM_3_skew', 'USED_MEM_3_kurt', 'CANCELLED_JOB_NUMS_4_mean', 'CANCELLED_JOB_NUMS_4_std', 'CANCELLED_JOB_NUMS_4_max', 'CANCELLED_JOB_NUMS_4_skew', 'CANCELLED_JOB_NUMS_4_kurt', 'CPU_USAGE_4_mean', 'CPU_USAGE_4_std', 'CPU_USAGE_4_max', 'CPU_USAGE_4_skew', 'CPU_USAGE_4_kurt', 'DISK_USAGE_4_mean', 'DISK_USAGE_4_std', 'DISK_USAGE_4_max', 'DISK_USAGE_4_skew', 'DISK_USAGE_4_kurt', 'FAILED_JOB_NUMS_4_mean', 'FAILED_JOB_NUMS_4_std', 'FAILED_JOB_NUMS_4_max', 'FAILED_JOB_NUMS_4_skew', 'FAILED_JOB_NUMS_4_kurt', 'LAUNCHING_JOB_NUMS_4_mean', 'LAUNCHING_JOB_NUMS_4_std', 'LAUNCHING_JOB_NUMS_4_max', 'LAUNCHING_JOB_NUMS_4_skew', 'LAUNCHING_JOB_NUMS_4_kurt', 'MEM_USAGE_4_mean', 'MEM_USAGE_4_std', 'MEM_USAGE_4_max', 'MEM_USAGE_4_skew', 'MEM_USAGE_4_kurt', 'RUNNING_JOB_NUMS_4_mean', 'RUNNING_JOB_NUMS_4_std', 'RUNNING_JOB_NUMS_4_max', 'RUNNING_JOB_NUMS_4_skew', 'RUNNING_JOB_NUMS_4_kurt', 'SUCCEED_JOB_NUMS_4_mean', 'SUCCEED_JOB_NUMS_4_std', 'SUCCEED_JOB_NUMS_4_max', 'SUCCEED_JOB_NUMS_4_skew', 'SUCCEED_JOB_NUMS_4_kurt', 'TO_RUN_JOBS_4_mean', 'TO_RUN_JOBS_4_std', 'TO_RUN_JOBS_4_max', 'TO_RUN_JOBS_4_skew', 'TO_RUN_JOBS_4_kurt', 'USED_CPU_4_mean', 'USED_CPU_4_std', 'USED_CPU_4_max', 'USED_CPU_4_skew', 'USED_CPU_4_kurt', 'USED_MEM_4_mean', 'USED_MEM_4_std', 'USED_MEM_4_max', 'USED_MEM_4_skew', 'USED_MEM_4_kurt', 'ID']\n"
     ]
    }
   ],
   "source": [
    "# 打印最终预处理后的数据集情况\n",
    "print('df_train({0}个变量：{1}'.format(len(list(df_train)), list(df_train)))\n",
    "print('='*50)\n",
    "print('df_test({0}个变量：{1}'.format(len(list(df_test)), list(df_test)))\n",
    "# 保存结果\n",
    "preprocess_name = '_v26'\n",
    "df_train.to_csv('../data/train{}.csv'.format(preprocess_name), index = False)\n",
    "df_test.to_csv('../data/test{}.csv'.format(preprocess_name), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
